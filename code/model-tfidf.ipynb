{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import string\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../data/beeradvocate.json.gz\"\n",
    "\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt', encoding=\"utf-8\"):\n",
    "        yield eval(l)\n",
    "\n",
    "data = []\n",
    "for l in tqdm(readGz(fpath)):\n",
    "    data.append(l)\n",
    "    # if len(data) >= 50000:\n",
    "    #     break\n",
    "data = data[:-1] # drop last datapoint (empty review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = set(list(zip(*string.punctuation)) + stopwords.words('english'))\n",
    "\n",
    "def preprocess(d):\n",
    "    tokens = gensim.utils.simple_preprocess(d)\n",
    "    return [t for t in tokens if t not in sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data = data[:100000] # take subset of data\n",
    "n = len(data)\n",
    "\n",
    "dataTrain = data[:int(n*0.9)]\n",
    "# dataVal = data[int(n*0.8):int(n*0.9)] \n",
    "dataTest = data[int(n*0.9):] \n",
    "\n",
    "Xtrain = [d['review/text'] for d in dataTrain]\n",
    "ytrain = [d['beer/style'] for d in dataTrain]\n",
    "\n",
    "Xtest = [d['review/text'] for d in dataTest]\n",
    "ytest = [d['beer/style'] for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "bow_params = {\n",
    "    'clf__C': [1,2,3,4,5,10,15,25,50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bow_model = GridSearchCV(bow_model, bow_params, cv=2)\n",
    "best_bow_model = best_bow_model.fit(Xtrain[:n_gs], ytrain[:n_gs])\n",
    "bow_preds = best_bow_model.predict(Xtest)\n",
    "print(np.mean(bow_preds == ytest)) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_bow_model.cv_results_)\n",
    "print(best_bow_model.best_params_)\n",
    "print(best_bow_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train best BOW model on full training set\n",
    "bow_model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression(C=25)),\n",
    "])\n",
    "\n",
    "bow_model.fit(Xtrain, ytrain)\n",
    "preds = bow_model.predict(Xtest)\n",
    "print(np.mean(preds == ytest)) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF\n",
    "tfidf_model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "tfidf_params = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 3)],\n",
    "    'vect__preprocessor': [preprocess, None],\n",
    "    'clf__C': np.arange(1,10,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tfidf_model = GridSearchCV(tfidf_model, tfidf_params, cv=2)\n",
    "best_tfidf_model = best_tfidf_model.fit(Xtrain[:n_gs], ytrain[:n_gs])\n",
    "tfidf_preds = best_tfidf_model.predict(Xtest)\n",
    "print(np.mean(tfidf_preds == ytest)) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_tfidf_model.cv_results_)\n",
    "print(best_tfidf_model.best_params_)\n",
    "print(best_tfidf_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train best TF-IDF on full training set\n",
    "tfidf_model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "tfidf_model.fit(Xtrain, ytrain, fit_params=best_tfidf_model.best_params_)\n",
    "preds = bow_model.predict(Xtest)\n",
    "print(np.mean(preds == ytest)) # accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
